---
title: "Lab6Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Lab6Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(Lab6)
```

# Overview
This vignette illustrates how the package [Lab6](https://github.com/nikostra/Lab6.git) works and it explains its different functionalities to solve the knapsack problem. For the knapsack problem we have n objects each with a different weight (w) and value (v). Using different algorithms, the objective is to find the optimal combination of objects that gives the maximum value possible while weighting less than a provided maximum weight (W).

We will include examples of the functions, as well as the running times and different optimizations carried out to reduce them as much as possible.

# Set up
First of all, the number of objects needs to be defined. The following code must be run to get the data:
```{r}
RNGversion(min(as.character(getRversion()),"3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 2000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )
```

# Knapsack Results
Now we will try each of the different algorithms:

* Brute force algorithm:
```{r}
brute_force_knapsack(x = knapsack_objects[1:12,], W =3500)
brute_force_knapsack(x = knapsack_objects[1:8,], W = 2000)
```

* Dynamic algorithm:
```{r}
knapsack_dynamic(x = knapsack_objects[1:12,], W =3500)
knapsack_dynamic(x = knapsack_objects[1:8,], W =2000)
```

* Greedy algorithm:
```{r}
greedy_knapsack(x = knapsack_objects[1:800,], W = 3500)
greedy_knapsack(x = knapsack_objects[1:1200,], W = 2000)
```
# Running times
Function running times before optimization:

* Brute force (n=16): 29.6s
  
* Dynamic programming (n=500): 2.22s
  
* Greedy algorithm (n=1000000): 286ms

Function running times after optimization:

* Brute force (n = 16): 1.04s
  
# Profiling insights:
After profiling the different functions, the only function which we could optimize was the brute force algorithm function. In brute_force_knapsack(), the rbind() function in the first version took up the most time.
The function was modified to initialize the element matrix and change each row instead of appending each row with rbind().

After optimization the runtime decreased significantly to 1.16s for n=16.

Additionally we implemented an alternative brute force algorithm (recursive_alg_knapsack() ) that uses recursion, which is also significantly faster than the default brute force algorithm. For n=16 it completes the computation in 902Âµs.

Compared to the other algorithms from this package, the performance of this recursive algorithm is better than the brute force and dynamic algorithms.

```{r}
recursive_alg_knapsack(knapsack_objects[1:12,],3500)
```

# Parallelizing brute force search
An optional argument has been added to choose whether the brute force algorithm should be run parallelized or not. The running times of both the parallelized version and the normal one have been compared for different sets of objects.

For n = 16 objects:

* Original time: 1.04s

* Parallelized time: 2.10s

For n = 20 objects:

* Original time: 19.11s

* Parallelized time: 16.09s

For n =22:

* Original time: 91.06s

* Parallelized time: 69.06s

For smaller sets of objects, the parallelized brute force search does not improve the running time, and it even lasts longer than the original version. This is due to the starting time of the cluster, which is considerable compared to the low running time in such cases.

For larger sets of objects the parallelized brute force improves the running time over the original brute force search. However, the running time is still much larger than the ones from other algorithms.
